{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Script for creating and training model, run on google colabs for fastest results"
      ],
      "metadata": {
        "id": "zhrHDcIlNnWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3p1gehQccUEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctKEIe4wimul"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import PIL\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "img_height = 128\n",
        "img_width = 128\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx0oLdzhFknL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f4f0e4b-05cb-4543-e01c-77a0cffab473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#connect your google drive to the notebook on google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCEMd_hkiXYW"
      },
      "outputs": [],
      "source": [
        "# numpy file of correct name needs to be uploaded in your google drive. change path as required\n",
        "# the numpy file contains all the data for training\n",
        "# use the create_training_data_array.py file to create this npy file\n",
        "td_array = np.load('drive/MyDrive/lego_project/td_array_7cat.npy', allow_pickle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwourKnvlPZQ",
        "outputId": "fd0c343f-d9ee-4fc0-fad3-a870c3462353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "# checking if GPU is enabled ingoogle collabs\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# functions for increasing contrast for images, using the second function at the moment as it has better results\n",
        "\n",
        "def increase_contrast_little(s):\n",
        "    npImage = s\n",
        "\n",
        "    min=np.min(npImage)        # result=144\n",
        "    max=np.max(npImage)        # result=216\n",
        "\n",
        "    # Make a LUT (Look-Up Table) to translate image values\n",
        "    LUT=np.zeros(256,dtype=np.uint8)\n",
        "    LUT[min:max+1]=np.linspace(start=0,stop=255,num=(max-min)+1,endpoint=True,dtype=np.uint8)\n",
        "    s_new = LUT[npImage]\n",
        "    return s_new\n",
        "\n",
        "def increase_contrast_more(s):\n",
        "    minval = np.percentile(s, 2)\n",
        "    maxval = np.percentile(s, 98)\n",
        "    npImage = np.clip(s, minval, maxval)\n",
        "\n",
        "    npImage = npImage.astype(int)\n",
        "\n",
        "    min=np.min(npImage)        # result=144\n",
        "    max=np.max(npImage)        # result=216\n",
        "\n",
        "    # Make a LUT (Look-Up Table) to translate image values\n",
        "    LUT=np.zeros(256,dtype=np.uint8)\n",
        "    LUT[min:max+1]=np.linspace(start=0,stop=255,num=(max-min)+1,endpoint=True,dtype=np.uint8)\n",
        "    s_clipped = LUT[npImage]\n",
        "    return s_clipped"
      ],
      "metadata": {
        "id": "7QnOLiRGn-da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ay8RzaNilMW"
      },
      "outputs": [],
      "source": [
        "# Convert the training data into list and randomize the order to get a fair split for testing and training data\n",
        "training_data = td_array.tolist()\n",
        "random.shuffle(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtO29pvqifzU"
      },
      "outputs": [],
      "source": [
        "# Create x and y lists for the images and its labels (i.e integers from 0 - 6) respectively\n",
        "x = []\n",
        "y = []  \n",
        "\n",
        "for piece, label in training_data:\n",
        "    x.append(piece)\n",
        "    y.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYIwVqaoyeuY"
      },
      "outputs": [],
      "source": [
        "x = np.array(list(map(increase_contrast_more, x))) #increase contrast of images\n",
        "x = np.array(x).reshape(-1,128,128,1) #reshape images for the model\n",
        "y = np.asarray(y)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2) # split the data into testing and training sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWM2m4Jmjb1X",
        "outputId": "b53d841a-aaad-4435-a253-7631ab6d2c43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "191/191 - 10s - loss: 1.8996 - accuracy: 0.1758 - val_loss: 1.8314 - val_accuracy: 0.1629 - 10s/epoch - 54ms/step\n",
            "Epoch 2/200\n",
            "191/191 - 6s - loss: 1.8118 - accuracy: 0.2264 - val_loss: 1.8302 - val_accuracy: 0.1654 - 6s/epoch - 30ms/step\n",
            "Epoch 3/200\n",
            "191/191 - 6s - loss: 1.7469 - accuracy: 0.2734 - val_loss: 1.7680 - val_accuracy: 0.2880 - 6s/epoch - 30ms/step\n",
            "Epoch 4/200\n",
            "191/191 - 6s - loss: 1.7202 - accuracy: 0.3118 - val_loss: 1.7892 - val_accuracy: 0.2175 - 6s/epoch - 30ms/step\n",
            "Epoch 5/200\n",
            "191/191 - 6s - loss: 1.6891 - accuracy: 0.3131 - val_loss: 1.6841 - val_accuracy: 0.3317 - 6s/epoch - 30ms/step\n",
            "Epoch 6/200\n",
            "191/191 - 6s - loss: 1.6595 - accuracy: 0.3284 - val_loss: 1.6486 - val_accuracy: 0.3174 - 6s/epoch - 29ms/step\n",
            "Epoch 7/200\n",
            "191/191 - 6s - loss: 1.6298 - accuracy: 0.3289 - val_loss: 1.7759 - val_accuracy: 0.2586 - 6s/epoch - 29ms/step\n",
            "Epoch 8/200\n",
            "191/191 - 6s - loss: 1.6129 - accuracy: 0.3312 - val_loss: 1.6146 - val_accuracy: 0.3350 - 6s/epoch - 30ms/step\n",
            "Epoch 9/200\n",
            "191/191 - 6s - loss: 1.5904 - accuracy: 0.3375 - val_loss: 1.5643 - val_accuracy: 0.3610 - 6s/epoch - 30ms/step\n",
            "Epoch 10/200\n",
            "191/191 - 6s - loss: 1.5567 - accuracy: 0.3475 - val_loss: 1.5298 - val_accuracy: 0.3879 - 6s/epoch - 30ms/step\n",
            "Epoch 11/200\n",
            "191/191 - 6s - loss: 1.5359 - accuracy: 0.3555 - val_loss: 1.5807 - val_accuracy: 0.3585 - 6s/epoch - 30ms/step\n",
            "Epoch 12/200\n",
            "191/191 - 6s - loss: 1.4632 - accuracy: 0.3963 - val_loss: 1.4086 - val_accuracy: 0.3846 - 6s/epoch - 30ms/step\n",
            "Epoch 13/200\n",
            "191/191 - 6s - loss: 1.3628 - accuracy: 0.4273 - val_loss: 1.3290 - val_accuracy: 0.4584 - 6s/epoch - 30ms/step\n",
            "Epoch 14/200\n",
            "191/191 - 6s - loss: 1.3013 - accuracy: 0.4410 - val_loss: 1.2101 - val_accuracy: 0.4878 - 6s/epoch - 30ms/step\n",
            "Epoch 15/200\n",
            "191/191 - 6s - loss: 1.1774 - accuracy: 0.5141 - val_loss: 1.1413 - val_accuracy: 0.5365 - 6s/epoch - 30ms/step\n",
            "Epoch 16/200\n",
            "191/191 - 6s - loss: 1.0987 - accuracy: 0.5414 - val_loss: 1.0804 - val_accuracy: 0.5441 - 6s/epoch - 30ms/step\n",
            "Epoch 17/200\n",
            "191/191 - 6s - loss: 1.0409 - accuracy: 0.6197 - val_loss: 1.0880 - val_accuracy: 0.6297 - 6s/epoch - 30ms/step\n",
            "Epoch 18/200\n",
            "191/191 - 6s - loss: 0.9914 - accuracy: 0.6438 - val_loss: 1.0274 - val_accuracy: 0.6255 - 6s/epoch - 30ms/step\n",
            "Epoch 19/200\n",
            "191/191 - 6s - loss: 0.9516 - accuracy: 0.6508 - val_loss: 0.9831 - val_accuracy: 0.6415 - 6s/epoch - 30ms/step\n",
            "Epoch 20/200\n",
            "191/191 - 6s - loss: 0.9421 - accuracy: 0.6615 - val_loss: 0.9132 - val_accuracy: 0.7053 - 6s/epoch - 30ms/step\n",
            "Epoch 21/200\n",
            "191/191 - 6s - loss: 0.9014 - accuracy: 0.6705 - val_loss: 0.8685 - val_accuracy: 0.7120 - 6s/epoch - 30ms/step\n",
            "Epoch 22/200\n",
            "191/191 - 6s - loss: 0.8953 - accuracy: 0.6751 - val_loss: 0.9655 - val_accuracy: 0.6524 - 6s/epoch - 30ms/step\n",
            "Epoch 23/200\n",
            "191/191 - 6s - loss: 0.8620 - accuracy: 0.6831 - val_loss: 0.8785 - val_accuracy: 0.7011 - 6s/epoch - 30ms/step\n",
            "Epoch 24/200\n",
            "191/191 - 6s - loss: 0.8526 - accuracy: 0.6846 - val_loss: 0.8214 - val_accuracy: 0.7238 - 6s/epoch - 30ms/step\n",
            "Epoch 25/200\n",
            "191/191 - 6s - loss: 0.8149 - accuracy: 0.7018 - val_loss: 0.9064 - val_accuracy: 0.6935 - 6s/epoch - 30ms/step\n",
            "Epoch 26/200\n",
            "191/191 - 6s - loss: 0.8154 - accuracy: 0.7010 - val_loss: 0.8668 - val_accuracy: 0.6759 - 6s/epoch - 30ms/step\n",
            "Epoch 27/200\n",
            "191/191 - 6s - loss: 0.8115 - accuracy: 0.6997 - val_loss: 0.7898 - val_accuracy: 0.7246 - 6s/epoch - 30ms/step\n",
            "Epoch 28/200\n",
            "191/191 - 6s - loss: 0.7931 - accuracy: 0.7047 - val_loss: 0.7726 - val_accuracy: 0.7112 - 6s/epoch - 30ms/step\n",
            "Epoch 29/200\n",
            "191/191 - 6s - loss: 0.7855 - accuracy: 0.7052 - val_loss: 0.7330 - val_accuracy: 0.7506 - 6s/epoch - 30ms/step\n",
            "Epoch 30/200\n",
            "191/191 - 6s - loss: 0.7450 - accuracy: 0.7236 - val_loss: 0.7294 - val_accuracy: 0.7431 - 6s/epoch - 30ms/step\n",
            "Epoch 31/200\n",
            "191/191 - 6s - loss: 0.7302 - accuracy: 0.7304 - val_loss: 0.7594 - val_accuracy: 0.7288 - 6s/epoch - 30ms/step\n",
            "Epoch 32/200\n",
            "191/191 - 6s - loss: 0.7409 - accuracy: 0.7293 - val_loss: 0.8757 - val_accuracy: 0.6759 - 6s/epoch - 30ms/step\n",
            "Epoch 33/200\n",
            "191/191 - 6s - loss: 0.7319 - accuracy: 0.7291 - val_loss: 0.9023 - val_accuracy: 0.6566 - 6s/epoch - 30ms/step\n",
            "Epoch 34/200\n",
            "191/191 - 6s - loss: 0.7195 - accuracy: 0.7268 - val_loss: 0.7434 - val_accuracy: 0.7288 - 6s/epoch - 30ms/step\n",
            "Epoch 35/200\n",
            "191/191 - 6s - loss: 0.6936 - accuracy: 0.7465 - val_loss: 0.7711 - val_accuracy: 0.7070 - 6s/epoch - 30ms/step\n",
            "Epoch 36/200\n",
            "191/191 - 6s - loss: 0.7075 - accuracy: 0.7402 - val_loss: 0.6921 - val_accuracy: 0.7573 - 6s/epoch - 30ms/step\n",
            "Epoch 37/200\n",
            "191/191 - 6s - loss: 0.6797 - accuracy: 0.7404 - val_loss: 0.6676 - val_accuracy: 0.7725 - 6s/epoch - 30ms/step\n",
            "Epoch 38/200\n",
            "191/191 - 6s - loss: 0.6925 - accuracy: 0.7396 - val_loss: 0.6421 - val_accuracy: 0.7733 - 6s/epoch - 30ms/step\n",
            "Epoch 39/200\n",
            "191/191 - 6s - loss: 0.6830 - accuracy: 0.7423 - val_loss: 0.7279 - val_accuracy: 0.7212 - 6s/epoch - 30ms/step\n",
            "Epoch 40/200\n",
            "191/191 - 6s - loss: 0.6679 - accuracy: 0.7535 - val_loss: 0.7575 - val_accuracy: 0.7162 - 6s/epoch - 30ms/step\n",
            "Epoch 41/200\n",
            "191/191 - 6s - loss: 0.6541 - accuracy: 0.7547 - val_loss: 0.6962 - val_accuracy: 0.7431 - 6s/epoch - 30ms/step\n",
            "Epoch 42/200\n",
            "191/191 - 6s - loss: 0.6470 - accuracy: 0.7604 - val_loss: 0.6713 - val_accuracy: 0.7657 - 6s/epoch - 30ms/step\n",
            "Epoch 43/200\n",
            "191/191 - 6s - loss: 0.6468 - accuracy: 0.7564 - val_loss: 0.6517 - val_accuracy: 0.7674 - 6s/epoch - 30ms/step\n",
            "Epoch 44/200\n",
            "191/191 - 6s - loss: 0.6484 - accuracy: 0.7539 - val_loss: 0.6730 - val_accuracy: 0.7657 - 6s/epoch - 30ms/step\n",
            "Epoch 45/200\n",
            "191/191 - 6s - loss: 0.6047 - accuracy: 0.7831 - val_loss: 0.6465 - val_accuracy: 0.7750 - 6s/epoch - 30ms/step\n",
            "Epoch 46/200\n",
            "191/191 - 6s - loss: 0.6222 - accuracy: 0.7730 - val_loss: 0.6341 - val_accuracy: 0.7901 - 6s/epoch - 30ms/step\n",
            "Epoch 47/200\n",
            "191/191 - 6s - loss: 0.6172 - accuracy: 0.7707 - val_loss: 0.7064 - val_accuracy: 0.7422 - 6s/epoch - 30ms/step\n",
            "Epoch 48/200\n",
            "191/191 - 6s - loss: 0.6040 - accuracy: 0.7768 - val_loss: 0.6157 - val_accuracy: 0.7867 - 6s/epoch - 30ms/step\n",
            "Epoch 49/200\n",
            "191/191 - 6s - loss: 0.6005 - accuracy: 0.7814 - val_loss: 0.6153 - val_accuracy: 0.7859 - 6s/epoch - 30ms/step\n",
            "Epoch 50/200\n",
            "191/191 - 6s - loss: 0.5946 - accuracy: 0.7835 - val_loss: 0.5898 - val_accuracy: 0.8035 - 6s/epoch - 30ms/step\n",
            "Epoch 51/200\n",
            "191/191 - 6s - loss: 0.5825 - accuracy: 0.7942 - val_loss: 0.6824 - val_accuracy: 0.7716 - 6s/epoch - 30ms/step\n",
            "Epoch 52/200\n",
            "191/191 - 6s - loss: 0.5727 - accuracy: 0.7913 - val_loss: 0.6784 - val_accuracy: 0.7590 - 6s/epoch - 30ms/step\n",
            "Epoch 53/200\n",
            "191/191 - 6s - loss: 0.5777 - accuracy: 0.7953 - val_loss: 0.6491 - val_accuracy: 0.7498 - 6s/epoch - 30ms/step\n",
            "Epoch 54/200\n",
            "191/191 - 6s - loss: 0.5568 - accuracy: 0.7953 - val_loss: 0.6421 - val_accuracy: 0.7775 - 6s/epoch - 30ms/step\n",
            "Epoch 55/200\n",
            "191/191 - 6s - loss: 0.5553 - accuracy: 0.7950 - val_loss: 0.6112 - val_accuracy: 0.7800 - 6s/epoch - 30ms/step\n",
            "Epoch 56/200\n",
            "191/191 - 6s - loss: 0.5540 - accuracy: 0.8003 - val_loss: 0.5779 - val_accuracy: 0.7968 - 6s/epoch - 30ms/step\n",
            "Epoch 57/200\n",
            "191/191 - 6s - loss: 0.5585 - accuracy: 0.7957 - val_loss: 0.5699 - val_accuracy: 0.8102 - 6s/epoch - 30ms/step\n",
            "Epoch 58/200\n",
            "191/191 - 6s - loss: 0.5420 - accuracy: 0.8007 - val_loss: 0.5168 - val_accuracy: 0.8237 - 6s/epoch - 30ms/step\n",
            "Epoch 59/200\n",
            "191/191 - 6s - loss: 0.5315 - accuracy: 0.8053 - val_loss: 0.4923 - val_accuracy: 0.8329 - 6s/epoch - 30ms/step\n",
            "Epoch 60/200\n",
            "191/191 - 6s - loss: 0.5301 - accuracy: 0.8070 - val_loss: 0.5542 - val_accuracy: 0.8069 - 6s/epoch - 30ms/step\n",
            "Epoch 61/200\n",
            "191/191 - 6s - loss: 0.5259 - accuracy: 0.8049 - val_loss: 0.5653 - val_accuracy: 0.8018 - 6s/epoch - 30ms/step\n",
            "Epoch 62/200\n",
            "191/191 - 6s - loss: 0.5153 - accuracy: 0.8104 - val_loss: 0.5654 - val_accuracy: 0.8069 - 6s/epoch - 30ms/step\n",
            "Epoch 63/200\n",
            "191/191 - 6s - loss: 0.5154 - accuracy: 0.8154 - val_loss: 0.4899 - val_accuracy: 0.8254 - 6s/epoch - 30ms/step\n",
            "Epoch 64/200\n",
            "191/191 - 6s - loss: 0.5000 - accuracy: 0.8209 - val_loss: 0.4831 - val_accuracy: 0.8346 - 6s/epoch - 30ms/step\n",
            "Epoch 65/200\n",
            "191/191 - 6s - loss: 0.4878 - accuracy: 0.8205 - val_loss: 0.5843 - val_accuracy: 0.8035 - 6s/epoch - 30ms/step\n",
            "Epoch 66/200\n",
            "191/191 - 6s - loss: 0.5015 - accuracy: 0.8207 - val_loss: 0.5102 - val_accuracy: 0.8237 - 6s/epoch - 30ms/step\n",
            "Epoch 67/200\n",
            "191/191 - 6s - loss: 0.4963 - accuracy: 0.8148 - val_loss: 0.4622 - val_accuracy: 0.8497 - 6s/epoch - 30ms/step\n",
            "Epoch 68/200\n",
            "191/191 - 6s - loss: 0.4831 - accuracy: 0.8253 - val_loss: 0.4956 - val_accuracy: 0.8287 - 6s/epoch - 30ms/step\n",
            "Epoch 69/200\n",
            "191/191 - 6s - loss: 0.4737 - accuracy: 0.8242 - val_loss: 0.6395 - val_accuracy: 0.7674 - 6s/epoch - 30ms/step\n",
            "Epoch 70/200\n",
            "191/191 - 6s - loss: 0.4685 - accuracy: 0.8303 - val_loss: 0.4498 - val_accuracy: 0.8505 - 6s/epoch - 30ms/step\n",
            "Epoch 71/200\n",
            "191/191 - 6s - loss: 0.4605 - accuracy: 0.8320 - val_loss: 0.4526 - val_accuracy: 0.8472 - 6s/epoch - 30ms/step\n",
            "Epoch 72/200\n",
            "191/191 - 6s - loss: 0.4678 - accuracy: 0.8356 - val_loss: 0.4691 - val_accuracy: 0.8522 - 6s/epoch - 30ms/step\n",
            "Epoch 73/200\n",
            "191/191 - 6s - loss: 0.4726 - accuracy: 0.8242 - val_loss: 0.4503 - val_accuracy: 0.8413 - 6s/epoch - 30ms/step\n",
            "Epoch 74/200\n",
            "191/191 - 6s - loss: 0.4431 - accuracy: 0.8389 - val_loss: 0.4796 - val_accuracy: 0.8270 - 6s/epoch - 30ms/step\n",
            "Epoch 75/200\n",
            "191/191 - 6s - loss: 0.4453 - accuracy: 0.8423 - val_loss: 0.3987 - val_accuracy: 0.8766 - 6s/epoch - 30ms/step\n",
            "Epoch 76/200\n",
            "191/191 - 6s - loss: 0.4493 - accuracy: 0.8354 - val_loss: 0.4146 - val_accuracy: 0.8598 - 6s/epoch - 30ms/step\n",
            "Epoch 77/200\n",
            "191/191 - 6s - loss: 0.4551 - accuracy: 0.8370 - val_loss: 0.4212 - val_accuracy: 0.8514 - 6s/epoch - 30ms/step\n",
            "Epoch 78/200\n",
            "191/191 - 6s - loss: 0.4444 - accuracy: 0.8379 - val_loss: 0.3759 - val_accuracy: 0.8825 - 6s/epoch - 30ms/step\n",
            "Epoch 79/200\n",
            "191/191 - 6s - loss: 0.4245 - accuracy: 0.8471 - val_loss: 0.4064 - val_accuracy: 0.8589 - 6s/epoch - 30ms/step\n",
            "Epoch 80/200\n",
            "191/191 - 6s - loss: 0.4311 - accuracy: 0.8450 - val_loss: 0.4495 - val_accuracy: 0.8514 - 6s/epoch - 30ms/step\n",
            "Epoch 81/200\n",
            "191/191 - 6s - loss: 0.4292 - accuracy: 0.8398 - val_loss: 0.3638 - val_accuracy: 0.8816 - 6s/epoch - 30ms/step\n",
            "Epoch 82/200\n",
            "191/191 - 6s - loss: 0.4194 - accuracy: 0.8467 - val_loss: 0.3775 - val_accuracy: 0.8766 - 6s/epoch - 30ms/step\n",
            "Epoch 83/200\n",
            "191/191 - 6s - loss: 0.4095 - accuracy: 0.8507 - val_loss: 0.3685 - val_accuracy: 0.8749 - 6s/epoch - 30ms/step\n",
            "Epoch 84/200\n",
            "191/191 - 6s - loss: 0.4048 - accuracy: 0.8515 - val_loss: 0.4169 - val_accuracy: 0.8438 - 6s/epoch - 30ms/step\n",
            "Epoch 85/200\n",
            "191/191 - 6s - loss: 0.4063 - accuracy: 0.8564 - val_loss: 0.4160 - val_accuracy: 0.8556 - 6s/epoch - 30ms/step\n",
            "Epoch 86/200\n",
            "191/191 - 6s - loss: 0.4149 - accuracy: 0.8452 - val_loss: 0.4422 - val_accuracy: 0.8514 - 6s/epoch - 30ms/step\n",
            "Epoch 87/200\n",
            "191/191 - 6s - loss: 0.3843 - accuracy: 0.8580 - val_loss: 0.3500 - val_accuracy: 0.8783 - 6s/epoch - 30ms/step\n",
            "Epoch 88/200\n",
            "191/191 - 6s - loss: 0.3888 - accuracy: 0.8599 - val_loss: 0.4341 - val_accuracy: 0.8447 - 6s/epoch - 30ms/step\n",
            "Epoch 89/200\n",
            "191/191 - 6s - loss: 0.4084 - accuracy: 0.8520 - val_loss: 0.4498 - val_accuracy: 0.8388 - 6s/epoch - 30ms/step\n",
            "Epoch 90/200\n",
            "191/191 - 6s - loss: 0.3790 - accuracy: 0.8662 - val_loss: 0.3955 - val_accuracy: 0.8657 - 6s/epoch - 30ms/step\n",
            "Epoch 91/200\n",
            "191/191 - 6s - loss: 0.3618 - accuracy: 0.8688 - val_loss: 0.3652 - val_accuracy: 0.8715 - 6s/epoch - 30ms/step\n",
            "Epoch 92/200\n",
            "191/191 - 6s - loss: 0.3694 - accuracy: 0.8604 - val_loss: 0.3543 - val_accuracy: 0.8858 - 6s/epoch - 30ms/step\n",
            "Epoch 93/200\n",
            "191/191 - 6s - loss: 0.3730 - accuracy: 0.8694 - val_loss: 0.3872 - val_accuracy: 0.8657 - 6s/epoch - 30ms/step\n",
            "Epoch 94/200\n",
            "191/191 - 6s - loss: 0.3579 - accuracy: 0.8751 - val_loss: 0.3567 - val_accuracy: 0.8808 - 6s/epoch - 30ms/step\n",
            "Epoch 95/200\n",
            "191/191 - 6s - loss: 0.3771 - accuracy: 0.8688 - val_loss: 0.3249 - val_accuracy: 0.9034 - 6s/epoch - 30ms/step\n",
            "Epoch 96/200\n",
            "191/191 - 6s - loss: 0.3599 - accuracy: 0.8723 - val_loss: 0.3364 - val_accuracy: 0.8850 - 6s/epoch - 30ms/step\n",
            "Epoch 97/200\n",
            "191/191 - 6s - loss: 0.3367 - accuracy: 0.8774 - val_loss: 0.3457 - val_accuracy: 0.8648 - 6s/epoch - 30ms/step\n",
            "Epoch 98/200\n",
            "191/191 - 6s - loss: 0.3710 - accuracy: 0.8667 - val_loss: 0.3745 - val_accuracy: 0.8833 - 6s/epoch - 30ms/step\n",
            "Epoch 99/200\n",
            "191/191 - 6s - loss: 0.3533 - accuracy: 0.8757 - val_loss: 0.3403 - val_accuracy: 0.8690 - 6s/epoch - 30ms/step\n",
            "Epoch 100/200\n",
            "191/191 - 6s - loss: 0.3416 - accuracy: 0.8746 - val_loss: 0.3973 - val_accuracy: 0.8690 - 6s/epoch - 30ms/step\n",
            "Epoch 101/200\n",
            "191/191 - 6s - loss: 0.3313 - accuracy: 0.8765 - val_loss: 0.3834 - val_accuracy: 0.8749 - 6s/epoch - 30ms/step\n",
            "Epoch 102/200\n",
            "191/191 - 6s - loss: 0.3457 - accuracy: 0.8709 - val_loss: 0.3538 - val_accuracy: 0.8808 - 6s/epoch - 30ms/step\n",
            "Epoch 103/200\n",
            "191/191 - 6s - loss: 0.3298 - accuracy: 0.8772 - val_loss: 0.3385 - val_accuracy: 0.8799 - 6s/epoch - 30ms/step\n",
            "Epoch 104/200\n",
            "191/191 - 6s - loss: 0.3355 - accuracy: 0.8748 - val_loss: 0.3066 - val_accuracy: 0.8950 - 6s/epoch - 30ms/step\n",
            "Epoch 105/200\n",
            "191/191 - 6s - loss: 0.3239 - accuracy: 0.8799 - val_loss: 0.3892 - val_accuracy: 0.8673 - 6s/epoch - 30ms/step\n",
            "Epoch 106/200\n",
            "191/191 - 6s - loss: 0.3065 - accuracy: 0.8910 - val_loss: 0.4333 - val_accuracy: 0.8539 - 6s/epoch - 30ms/step\n",
            "Epoch 107/200\n",
            "191/191 - 6s - loss: 0.3175 - accuracy: 0.8820 - val_loss: 0.3730 - val_accuracy: 0.8866 - 6s/epoch - 30ms/step\n",
            "Epoch 108/200\n",
            "191/191 - 6s - loss: 0.3164 - accuracy: 0.8835 - val_loss: 0.2982 - val_accuracy: 0.9001 - 6s/epoch - 30ms/step\n",
            "Epoch 109/200\n",
            "191/191 - 6s - loss: 0.3093 - accuracy: 0.8887 - val_loss: 0.3447 - val_accuracy: 0.8900 - 6s/epoch - 30ms/step\n",
            "Epoch 110/200\n",
            "191/191 - 6s - loss: 0.2877 - accuracy: 0.8887 - val_loss: 0.3447 - val_accuracy: 0.8783 - 6s/epoch - 30ms/step\n",
            "Epoch 111/200\n",
            "191/191 - 6s - loss: 0.3035 - accuracy: 0.8902 - val_loss: 0.3163 - val_accuracy: 0.8892 - 6s/epoch - 30ms/step\n",
            "Epoch 112/200\n",
            "191/191 - 6s - loss: 0.2967 - accuracy: 0.8885 - val_loss: 0.3678 - val_accuracy: 0.8741 - 6s/epoch - 30ms/step\n",
            "Epoch 113/200\n",
            "191/191 - 6s - loss: 0.2899 - accuracy: 0.8984 - val_loss: 0.2758 - val_accuracy: 0.9152 - 6s/epoch - 30ms/step\n",
            "Epoch 114/200\n",
            "191/191 - 6s - loss: 0.2971 - accuracy: 0.8965 - val_loss: 0.3186 - val_accuracy: 0.8942 - 6s/epoch - 30ms/step\n",
            "Epoch 115/200\n",
            "191/191 - 6s - loss: 0.2775 - accuracy: 0.8965 - val_loss: 0.2999 - val_accuracy: 0.8992 - 6s/epoch - 30ms/step\n",
            "Epoch 116/200\n",
            "191/191 - 6s - loss: 0.2787 - accuracy: 0.8956 - val_loss: 0.2812 - val_accuracy: 0.9043 - 6s/epoch - 30ms/step\n",
            "Epoch 117/200\n",
            "191/191 - 6s - loss: 0.2971 - accuracy: 0.8929 - val_loss: 0.2682 - val_accuracy: 0.9068 - 6s/epoch - 30ms/step\n",
            "Epoch 118/200\n",
            "191/191 - 6s - loss: 0.2672 - accuracy: 0.9009 - val_loss: 0.3222 - val_accuracy: 0.8950 - 6s/epoch - 30ms/step\n",
            "Epoch 119/200\n",
            "191/191 - 6s - loss: 0.2905 - accuracy: 0.9013 - val_loss: 0.2926 - val_accuracy: 0.9102 - 6s/epoch - 30ms/step\n",
            "Epoch 120/200\n",
            "191/191 - 6s - loss: 0.2717 - accuracy: 0.8973 - val_loss: 0.2978 - val_accuracy: 0.8984 - 6s/epoch - 30ms/step\n",
            "Epoch 121/200\n",
            "191/191 - 6s - loss: 0.2580 - accuracy: 0.9078 - val_loss: 0.3505 - val_accuracy: 0.8850 - 6s/epoch - 30ms/step\n",
            "Epoch 122/200\n",
            "191/191 - 6s - loss: 0.2632 - accuracy: 0.9024 - val_loss: 0.2993 - val_accuracy: 0.9060 - 6s/epoch - 30ms/step\n",
            "Epoch 123/200\n",
            "191/191 - 6s - loss: 0.2579 - accuracy: 0.9099 - val_loss: 0.3137 - val_accuracy: 0.9018 - 6s/epoch - 30ms/step\n",
            "Epoch 124/200\n",
            "191/191 - 6s - loss: 0.2816 - accuracy: 0.8988 - val_loss: 0.2962 - val_accuracy: 0.9018 - 6s/epoch - 30ms/step\n",
            "Epoch 125/200\n",
            "191/191 - 6s - loss: 0.2649 - accuracy: 0.9042 - val_loss: 0.3404 - val_accuracy: 0.8892 - 6s/epoch - 30ms/step\n",
            "Epoch 126/200\n",
            "191/191 - 6s - loss: 0.2621 - accuracy: 0.9003 - val_loss: 0.2956 - val_accuracy: 0.9043 - 6s/epoch - 30ms/step\n",
            "Epoch 127/200\n",
            "191/191 - 6s - loss: 0.2667 - accuracy: 0.9057 - val_loss: 0.3207 - val_accuracy: 0.8959 - 6s/epoch - 30ms/step\n",
            "Epoch 128/200\n",
            "191/191 - 6s - loss: 0.2638 - accuracy: 0.9038 - val_loss: 0.2767 - val_accuracy: 0.9085 - 6s/epoch - 30ms/step\n",
            "Epoch 129/200\n",
            "191/191 - 6s - loss: 0.2565 - accuracy: 0.9059 - val_loss: 0.3086 - val_accuracy: 0.8976 - 6s/epoch - 30ms/step\n",
            "Epoch 130/200\n",
            "191/191 - 6s - loss: 0.2457 - accuracy: 0.9164 - val_loss: 0.2890 - val_accuracy: 0.9026 - 6s/epoch - 30ms/step\n",
            "Epoch 131/200\n",
            "191/191 - 6s - loss: 0.2517 - accuracy: 0.9080 - val_loss: 0.2831 - val_accuracy: 0.9068 - 6s/epoch - 30ms/step\n",
            "Epoch 132/200\n",
            "191/191 - 6s - loss: 0.2437 - accuracy: 0.9097 - val_loss: 0.2904 - val_accuracy: 0.9051 - 6s/epoch - 30ms/step\n",
            "Epoch 133/200\n",
            "191/191 - 6s - loss: 0.2479 - accuracy: 0.9087 - val_loss: 0.2390 - val_accuracy: 0.9328 - 6s/epoch - 30ms/step\n",
            "Epoch 134/200\n",
            "191/191 - 6s - loss: 0.2411 - accuracy: 0.9137 - val_loss: 0.3416 - val_accuracy: 0.8908 - 6s/epoch - 30ms/step\n",
            "Epoch 135/200\n",
            "191/191 - 6s - loss: 0.2748 - accuracy: 0.8996 - val_loss: 0.2838 - val_accuracy: 0.9009 - 6s/epoch - 30ms/step\n",
            "Epoch 136/200\n",
            "191/191 - 6s - loss: 0.2454 - accuracy: 0.9124 - val_loss: 0.2851 - val_accuracy: 0.9093 - 6s/epoch - 30ms/step\n",
            "Epoch 137/200\n",
            "191/191 - 6s - loss: 0.2484 - accuracy: 0.9047 - val_loss: 0.3331 - val_accuracy: 0.8950 - 6s/epoch - 30ms/step\n",
            "Epoch 138/200\n",
            "191/191 - 6s - loss: 0.2403 - accuracy: 0.9126 - val_loss: 0.3184 - val_accuracy: 0.9043 - 6s/epoch - 30ms/step\n",
            "Epoch 139/200\n",
            "191/191 - 6s - loss: 0.2303 - accuracy: 0.9181 - val_loss: 0.2648 - val_accuracy: 0.9085 - 6s/epoch - 30ms/step\n",
            "Epoch 140/200\n",
            "191/191 - 6s - loss: 0.2448 - accuracy: 0.9139 - val_loss: 0.3233 - val_accuracy: 0.9001 - 6s/epoch - 30ms/step\n",
            "Epoch 141/200\n",
            "191/191 - 6s - loss: 0.2724 - accuracy: 0.9072 - val_loss: 0.2627 - val_accuracy: 0.9169 - 6s/epoch - 30ms/step\n",
            "Epoch 142/200\n",
            "191/191 - 6s - loss: 0.2434 - accuracy: 0.9093 - val_loss: 0.3618 - val_accuracy: 0.8892 - 6s/epoch - 30ms/step\n",
            "Epoch 143/200\n",
            "191/191 - 6s - loss: 0.2365 - accuracy: 0.9179 - val_loss: 0.3222 - val_accuracy: 0.8967 - 6s/epoch - 30ms/step\n",
            "Epoch 144/200\n",
            "191/191 - 6s - loss: 0.2314 - accuracy: 0.9219 - val_loss: 0.2544 - val_accuracy: 0.9152 - 6s/epoch - 30ms/step\n",
            "Epoch 145/200\n",
            "191/191 - 6s - loss: 0.2164 - accuracy: 0.9240 - val_loss: 0.3061 - val_accuracy: 0.8959 - 6s/epoch - 30ms/step\n",
            "Epoch 146/200\n",
            "191/191 - 6s - loss: 0.2420 - accuracy: 0.9152 - val_loss: 0.3037 - val_accuracy: 0.9034 - 6s/epoch - 30ms/step\n",
            "Epoch 147/200\n",
            "191/191 - 6s - loss: 0.2443 - accuracy: 0.9108 - val_loss: 0.2830 - val_accuracy: 0.9102 - 6s/epoch - 30ms/step\n",
            "Epoch 148/200\n",
            "191/191 - 6s - loss: 0.2401 - accuracy: 0.9150 - val_loss: 0.2711 - val_accuracy: 0.9186 - 6s/epoch - 30ms/step\n",
            "Epoch 149/200\n",
            "191/191 - 6s - loss: 0.2313 - accuracy: 0.9154 - val_loss: 0.2561 - val_accuracy: 0.9244 - 6s/epoch - 30ms/step\n",
            "Epoch 150/200\n",
            "191/191 - 6s - loss: 0.2281 - accuracy: 0.9162 - val_loss: 0.2524 - val_accuracy: 0.9286 - 6s/epoch - 30ms/step\n",
            "Epoch 151/200\n",
            "191/191 - 6s - loss: 0.2177 - accuracy: 0.9158 - val_loss: 0.2736 - val_accuracy: 0.9160 - 6s/epoch - 30ms/step\n",
            "Epoch 152/200\n",
            "191/191 - 6s - loss: 0.2311 - accuracy: 0.9164 - val_loss: 0.2836 - val_accuracy: 0.9160 - 6s/epoch - 29ms/step\n",
            "Epoch 153/200\n",
            "191/191 - 6s - loss: 0.2255 - accuracy: 0.9189 - val_loss: 0.2864 - val_accuracy: 0.9093 - 6s/epoch - 30ms/step\n",
            "Epoch 154/200\n",
            "191/191 - 6s - loss: 0.2187 - accuracy: 0.9223 - val_loss: 0.2589 - val_accuracy: 0.9152 - 6s/epoch - 30ms/step\n",
            "Epoch 155/200\n",
            "191/191 - 6s - loss: 0.2174 - accuracy: 0.9238 - val_loss: 0.3310 - val_accuracy: 0.8917 - 6s/epoch - 30ms/step\n",
            "Epoch 156/200\n",
            "191/191 - 6s - loss: 0.2254 - accuracy: 0.9185 - val_loss: 0.2509 - val_accuracy: 0.9186 - 6s/epoch - 30ms/step\n",
            "Epoch 157/200\n",
            "191/191 - 6s - loss: 0.2391 - accuracy: 0.9173 - val_loss: 0.2872 - val_accuracy: 0.9118 - 6s/epoch - 30ms/step\n",
            "Epoch 158/200\n",
            "191/191 - 6s - loss: 0.2265 - accuracy: 0.9225 - val_loss: 0.2846 - val_accuracy: 0.9135 - 6s/epoch - 30ms/step\n",
            "Epoch 159/200\n",
            "191/191 - 6s - loss: 0.2146 - accuracy: 0.9240 - val_loss: 0.2881 - val_accuracy: 0.9060 - 6s/epoch - 30ms/step\n",
            "Epoch 160/200\n",
            "191/191 - 6s - loss: 0.2183 - accuracy: 0.9225 - val_loss: 0.2994 - val_accuracy: 0.9034 - 6s/epoch - 30ms/step\n",
            "Epoch 161/200\n",
            "191/191 - 6s - loss: 0.2118 - accuracy: 0.9265 - val_loss: 0.3048 - val_accuracy: 0.9093 - 6s/epoch - 30ms/step\n",
            "Epoch 162/200\n",
            "191/191 - 6s - loss: 0.2180 - accuracy: 0.9194 - val_loss: 0.2550 - val_accuracy: 0.9228 - 6s/epoch - 30ms/step\n",
            "Epoch 163/200\n",
            "191/191 - 6s - loss: 0.2222 - accuracy: 0.9196 - val_loss: 0.2936 - val_accuracy: 0.8967 - 6s/epoch - 30ms/step\n",
            "Epoch 164/200\n",
            "191/191 - 6s - loss: 0.2131 - accuracy: 0.9280 - val_loss: 0.2975 - val_accuracy: 0.9144 - 6s/epoch - 30ms/step\n",
            "Epoch 165/200\n",
            "191/191 - 6s - loss: 0.2276 - accuracy: 0.9152 - val_loss: 0.2770 - val_accuracy: 0.9278 - 6s/epoch - 30ms/step\n",
            "Epoch 166/200\n",
            "191/191 - 6s - loss: 0.2062 - accuracy: 0.9255 - val_loss: 0.2899 - val_accuracy: 0.9144 - 6s/epoch - 29ms/step\n",
            "Epoch 167/200\n",
            "191/191 - 6s - loss: 0.1888 - accuracy: 0.9284 - val_loss: 0.2252 - val_accuracy: 0.9278 - 6s/epoch - 30ms/step\n",
            "Epoch 168/200\n",
            "191/191 - 6s - loss: 0.2114 - accuracy: 0.9213 - val_loss: 0.3143 - val_accuracy: 0.8984 - 6s/epoch - 30ms/step\n",
            "Epoch 169/200\n",
            "191/191 - 6s - loss: 0.2253 - accuracy: 0.9244 - val_loss: 0.2731 - val_accuracy: 0.9261 - 6s/epoch - 30ms/step\n",
            "Epoch 170/200\n",
            "191/191 - 6s - loss: 0.2241 - accuracy: 0.9177 - val_loss: 0.2833 - val_accuracy: 0.9194 - 6s/epoch - 30ms/step\n",
            "Epoch 171/200\n",
            "191/191 - 6s - loss: 0.2079 - accuracy: 0.9231 - val_loss: 0.2732 - val_accuracy: 0.9320 - 6s/epoch - 29ms/step\n",
            "Epoch 172/200\n",
            "191/191 - 6s - loss: 0.2033 - accuracy: 0.9250 - val_loss: 0.2211 - val_accuracy: 0.9286 - 6s/epoch - 30ms/step\n",
            "Epoch 173/200\n",
            "191/191 - 6s - loss: 0.2036 - accuracy: 0.9238 - val_loss: 0.2762 - val_accuracy: 0.9160 - 6s/epoch - 29ms/step\n",
            "Epoch 174/200\n",
            "191/191 - 6s - loss: 0.2127 - accuracy: 0.9248 - val_loss: 0.2965 - val_accuracy: 0.9135 - 6s/epoch - 30ms/step\n",
            "Epoch 175/200\n",
            "191/191 - 6s - loss: 0.1966 - accuracy: 0.9280 - val_loss: 0.2591 - val_accuracy: 0.9278 - 6s/epoch - 30ms/step\n",
            "Epoch 176/200\n",
            "191/191 - 6s - loss: 0.2070 - accuracy: 0.9229 - val_loss: 0.2588 - val_accuracy: 0.9286 - 6s/epoch - 30ms/step\n",
            "Epoch 177/200\n",
            "191/191 - 6s - loss: 0.1901 - accuracy: 0.9286 - val_loss: 0.3472 - val_accuracy: 0.8967 - 6s/epoch - 30ms/step\n",
            "Epoch 178/200\n",
            "191/191 - 6s - loss: 0.2068 - accuracy: 0.9257 - val_loss: 0.2832 - val_accuracy: 0.9236 - 6s/epoch - 30ms/step\n",
            "Epoch 179/200\n",
            "191/191 - 6s - loss: 0.1943 - accuracy: 0.9330 - val_loss: 0.2488 - val_accuracy: 0.9202 - 6s/epoch - 30ms/step\n",
            "Epoch 180/200\n",
            "191/191 - 6s - loss: 0.1829 - accuracy: 0.9336 - val_loss: 0.2446 - val_accuracy: 0.9286 - 6s/epoch - 29ms/step\n",
            "Epoch 181/200\n",
            "191/191 - 6s - loss: 0.2037 - accuracy: 0.9303 - val_loss: 0.3090 - val_accuracy: 0.9093 - 6s/epoch - 29ms/step\n",
            "Epoch 182/200\n",
            "191/191 - 6s - loss: 0.2118 - accuracy: 0.9269 - val_loss: 0.3301 - val_accuracy: 0.9001 - 6s/epoch - 29ms/step\n",
            "Epoch 183/200\n",
            "191/191 - 6s - loss: 0.1968 - accuracy: 0.9280 - val_loss: 0.2938 - val_accuracy: 0.9076 - 6s/epoch - 29ms/step\n",
            "Epoch 184/200\n",
            "191/191 - 6s - loss: 0.1983 - accuracy: 0.9257 - val_loss: 0.2239 - val_accuracy: 0.9312 - 6s/epoch - 30ms/step\n",
            "Epoch 185/200\n",
            "191/191 - 6s - loss: 0.2167 - accuracy: 0.9259 - val_loss: 0.2743 - val_accuracy: 0.9194 - 6s/epoch - 29ms/step\n",
            "Epoch 186/200\n",
            "191/191 - 6s - loss: 0.1852 - accuracy: 0.9307 - val_loss: 0.2109 - val_accuracy: 0.9404 - 6s/epoch - 29ms/step\n",
            "Epoch 187/200\n",
            "191/191 - 6s - loss: 0.2032 - accuracy: 0.9294 - val_loss: 0.2236 - val_accuracy: 0.9312 - 6s/epoch - 29ms/step\n",
            "Epoch 188/200\n",
            "191/191 - 6s - loss: 0.1854 - accuracy: 0.9322 - val_loss: 0.2497 - val_accuracy: 0.9228 - 6s/epoch - 30ms/step\n",
            "Epoch 189/200\n",
            "191/191 - 6s - loss: 0.1897 - accuracy: 0.9307 - val_loss: 0.2613 - val_accuracy: 0.9312 - 6s/epoch - 30ms/step\n",
            "Epoch 190/200\n",
            "191/191 - 6s - loss: 0.2008 - accuracy: 0.9307 - val_loss: 0.2630 - val_accuracy: 0.9144 - 6s/epoch - 30ms/step\n",
            "Epoch 191/200\n",
            "191/191 - 6s - loss: 0.1881 - accuracy: 0.9320 - val_loss: 0.2386 - val_accuracy: 0.9244 - 6s/epoch - 29ms/step\n",
            "Epoch 192/200\n",
            "191/191 - 6s - loss: 0.1948 - accuracy: 0.9326 - val_loss: 0.2785 - val_accuracy: 0.9211 - 6s/epoch - 30ms/step\n",
            "Epoch 193/200\n",
            "191/191 - 6s - loss: 0.1969 - accuracy: 0.9284 - val_loss: 0.2363 - val_accuracy: 0.9261 - 6s/epoch - 29ms/step\n",
            "Epoch 194/200\n",
            "191/191 - 6s - loss: 0.2048 - accuracy: 0.9282 - val_loss: 0.2700 - val_accuracy: 0.9152 - 6s/epoch - 29ms/step\n",
            "Epoch 195/200\n",
            "191/191 - 6s - loss: 0.1963 - accuracy: 0.9318 - val_loss: 0.3045 - val_accuracy: 0.9051 - 6s/epoch - 29ms/step\n",
            "Epoch 196/200\n",
            "191/191 - 6s - loss: 0.1895 - accuracy: 0.9328 - val_loss: 0.2360 - val_accuracy: 0.9278 - 6s/epoch - 29ms/step\n",
            "Epoch 197/200\n",
            "191/191 - 6s - loss: 0.1876 - accuracy: 0.9305 - val_loss: 0.2235 - val_accuracy: 0.9278 - 6s/epoch - 30ms/step\n",
            "Epoch 198/200\n",
            "191/191 - 6s - loss: 0.2012 - accuracy: 0.9292 - val_loss: 0.2263 - val_accuracy: 0.9345 - 6s/epoch - 29ms/step\n",
            "Epoch 199/200\n",
            "191/191 - 6s - loss: 0.1784 - accuracy: 0.9360 - val_loss: 0.2212 - val_accuracy: 0.9328 - 6s/epoch - 29ms/step\n",
            "Epoch 200/200\n",
            "191/191 - 6s - loss: 0.1736 - accuracy: 0.9366 - val_loss: 0.2509 - val_accuracy: 0.9345 - 6s/epoch - 29ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe14e120a90>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\",\n",
        "                        input_shape=(img_height,\n",
        "                                    img_width,\n",
        "                                    1)),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.1),\n",
        "    ])\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        data_augmentation,\n",
        "    \n",
        "        layers.Rescaling(1./255, input_shape = (img_height,img_width,1)), #normalize the data input\n",
        "\n",
        "        layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "        layers.Conv2D(64, 3, padding=\"same\", activation='relu'), #should this be 16 or 32 units? try with more data\n",
        "        layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "        layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2,2)),\n",
        "        \n",
        "        layers.Conv2D(16, 3, padding=\"same\", activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2,2)),\n",
        "        \n",
        "        layers.Dropout(0.1),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(10,activation = 'relu'),\n",
        "        layers.Dense(7,activation='softmax'), # number of output classes\n",
        "        # softmax activation on the last layer will output a probability distribution over the output classes. The sum \n",
        "        # of all the probabilities will be equal to 1\n",
        "        \n",
        "    ]\n",
        ")        \n",
        "\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=[keras.losses.SparseCategoricalCrossentropy(from_logits=False),],\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "# epochs = 25\n",
        "#model_history = \n",
        "\n",
        "# if you don't need the training graphs, can just run model.fit(...)\n",
        "# model.fit(x_train, y_train, epochs=200, verbose=2, validation_data=(x_test,y_test), batch_size=25)  #i think 25/32 is the best batch size \n",
        "\n",
        "# run this to get graphs of the training progress\n",
        "model_history = model.fit(x_train, y_train, epochs=200, verbose=2, validation_data=(x_test,y_test), batch_size=25)  #i think 25/32 is the best batch size \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTgvkT0cjkYq",
        "outputId": "7e1c9fdb-7ec6-455f-bb26-9de374046eb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[176   1   8   0   1   5   1]\n",
            " [  6 212   0   1   0   9   2]\n",
            " [ 11   0 181   0   1   0   0]\n",
            " [  0   1   0 165   1   0   0]\n",
            " [  0   0   2   1 105   0   0]\n",
            " [  5   8   0   0   0 193   0]\n",
            " [  2   9   0   1   1   1  81]]\n"
          ]
        }
      ],
      "source": [
        "# to get confusion matrix for model with test data\n",
        "# By definition a confusion matrix C is such that C(i,j) is equal to the number of observations known to be in group i and predicted to be in group j\n",
        "# columns are predictions, rows are actual labels\n",
        "\n",
        "prediction = model.predict(x_test)\n",
        "classes_x=np.argmax(prediction,axis=1)\n",
        "cm = confusion_matrix(y_test, classes_x)\n",
        "print(cm)\n",
        "#print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model as a SavedModel.\n",
        "model.save('drive/MyDrive/lego_project/saved_model/final_model')  \n",
        "# make sure that cd is at C:/Users/amosk/Python then run the program. This will \n",
        "# create a SavedModel named my_model in the saved_model folder inside RPI3_project folder\n",
        "\n",
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('drive/MyDrive/lego_project/saved_model/final_model') # path to the SavedModel directory\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('drive/MyDrive/lego_project/model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)  #save tfllite model as model.tflite\n"
      ],
      "metadata": {
        "id": "UxhYEy5TRPfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to load model\n",
        "model_loaded = tf.keras.models.load_model('drive/MyDrive/lego_project/saved_model/my_model')"
      ],
      "metadata": {
        "id": "5FjOX5eYgt0_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}